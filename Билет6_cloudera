Билет №6.
2.	Выполнить операции по аналитике данных в экосистеме cloudera. Провести обработку больших данных на основе Pig:
-	В интерактивном режиме через Терминал, запустить оболочку Pig; 
-	В Hue перейти в редактор Pig через Query > Editor > Pig;
-	Запустите следующий скрипт/команды, чтобы загрузить и отобразить первые десять строк из файла геолокации:
geoloc = LOAD 'geoloc/geolocation.csv' USING PigStorage(',') AS (truckid,driverid,event,latitude,longitude,city,state,velocity,event_ind,idling_ind);

geoloc_limit = LIMIT geoloc 10;

DUMP geoloc_limit;
-	Проверить папку «results», хранящуюся в HDFS, по строке STORE result. Пояснить полученные результаты;
-	Проанализировать журналы на новой вкладке Hadoop > YARN Resource Manager в Firefox;
-	Подсчитать список различных городов, посещенных каждым идентификатором грузовика, и среднюю скорость для каждого идентификатора грузовика.
Постановка задачи представлена по ссылке:  https://github.com/BosenkoTM/cloudera-quickstart/blob/main/README.md

Решение:
Общие моменты от Босенко Т.М.: https://github.com/BosenkoTM/cloudera-quickstart/blob/main/README.md
Конкретно наша задача: https://github.com/BosenkoTM/cloudera-quickstart/blob/main/hw_3-2_hdfs_pig.md
Скачать архив с виртуалкой по ссылке: https://downloads.cloudera.com/demo_vm/virtualbox/cloudera-quickstart-vm-5.13.0-0-virtualbox.zip
Разархивировать, в папке будет 2 файла:
 
Далее открываем программу Virtual Box.
 
Выберите в качестве конфигурации этот файл:

 
Установить для виртуальной машины диапазон виртуальной памяти от 4 до 8 ГБ ОЗУ (у меня более 4000 МБ, это около 4 ГБ). Плюс я увеличила количество процессоров с 1 до 2, если можете больше, делайте больше, но не отдавайте все процессоры компа (у меня всего 4). 
PS: оказалось, что это очень мало, машина работала очень медленно.
 
Далее запустите машину.
Чтобы растянуть окно машины можете нажать сюда (чтобы отменить надо нажать правый ctrl + C):
 
Чтобы включить копипасту, включите двунаправленный буфер обмена:
 
☹  Машина очень медленная, не спешите по 10 раз жмякать, надо ждать после каждого клика.
Откройте терминал:
 
Установим разрешения на запись пользователем hdfs. Запустите следующий скрипт.
sudo su -
su hdfs
hdfs dfs -chmod -R 777 /tmp
 
Откройте новый терминал и введите команду для открытия браузера:
firefox
 
В браузере перейдите на закладку Heu. Учетные данные: cloudera/cloudera.
 
Создать каталог ex_3_2:
mkdir ex_3_2
Пререйти в каталог ex_3_2:
cd ex_3_2
 

Скачать данные Geolocation data:
wget https://community.cloudera.com/legacyfs/online/attachments/2768-geolocation.zip
 
разархивировать данные
unzip 2768-geolocation.zip
 
В Hue, выбрать Browsers > Files
 
 
Создайте новый каталог в HDFS с именем geoloc/ внутри HDFS из Hue
 
 
Заходим в папку
 
Загрузите Geolocation.csv и trucks.csv в только что созданную папку geoloc/.
 
 
 
Зажимая shift, можете выбрать сразу оба файла, open.
 
 
В Hue перейти в редактор Pig через Query > Editor > Pig
 
Если прям очень долго грузится, обновите (еще раз нажмите на Hue).
Если выходит такая штука, нажимайте Continue (у меня вылезала постонно).
 
Сначала убедиться в запуске Dataflow инструмента Oozie.
Через + добавьте в браузере новую вкладку и выберите Oozie.
 
У меня там пока так:
 
Возвращаемся на вкладку с Hue и вставляем этот скрипт (это скрипт из gita):
geoloc = LOAD 'geoloc/geolocation.csv' USING PigStorage(',') AS (truckid:chararray, 
driverid:chararray, event:chararray, latitude:double, longitude:double, city:chararray, 
state:chararray, velocity:double, event_ind:long, idling_ind:long);
geoloc_limit = LIMIT geoloc 10;
STORE geoloc_limit INTO 'results-geoloc'; 
DUMP geoloc_limit;
И запускаем его:
 
В самом билете у нас немного другой скрипт:
geoloc = LOAD 'geoloc/geolocation.csv' USING PigStorage(',') AS
(truckid,driverid,event,latitude,longitude,city,state,velocity,event_ind,idling_ind);
geoloc_limit = LIMIT geoloc 10;
DUMP geoloc_limit;
GPT говорит, что разница между ними следующая: «В первом скрипте после загрузки данных из файла geolocation.csv они также выводятся на экран с помощью DUMP, но затем ограниченное количество строк (10) сохраняется в файл 'results-geoloc'. Во втором скрипте после загрузки данных из файла geolocation.csv они остаются в памяти Pig и выводятся на экран с помощью DUMP. Данные не сохраняются нигде еще». 
Поскольку по заданию мы должны будем просмотреть результат в папке, нам подходит скрипт из гита, а не из билета.
А тем временем, если перейти на вкладку с Oozie и обновить там, мы увидим:
 
Если нажать по Джобу 2 раза и перейти в Job Dag, должен быть его рисунок. 
 
Вернемся к файлам (см. стр. 6). Там появилась новая директория, зайдем в нее:
 
Далее идем сюда:
 
А вот и результат:
 
Нам надо пояснить этот результат. Вот, как помог GPT:
“Данный скрипт Pig загружает данные из файла geolocation.csv в отношении геолокации транспортных средств. Затем устанавливает ограничение на количество строк (10 строк) и сохраняет полученные данные в файл 'results-geoloc'. Наконец, выводит первые 10 строк данных.
Полученные данные представляют собой информацию о различных транспортных средствах, таких как идентификатор грузовика (truckid), идентификатор водителя (driverid), тип события (event), широту и долготу местоположения (latitude и longitude), город (city), штат (state), скорость (velocity), индикатор события (event_ind) и индикатор простоя (idling_ind).
Например, первая строка показывает данные о грузовике с идентификатором A19 и водителем A19, который находится в городе San Pablo, штат Калифорния, с нулевой скоростью и показателем события 0 (нормальное событие) и показателем простоя 1.
Аналогично, остальные строки представляют информацию о различных грузовиках, их расположении, скорости и событиях.”
Проанализировать журналы на новой вкладке Hadoop > YARN Resource Manager в Firefox. Для этого через + создайте новую вкладку в браузере, а там:
 
Там будет:
 
«В разделе Cluster Metrics отображается количество приложений, которые были отправлены, ожидают выполнения, выполняются и завершены, количество работающих контейнеров, используемая оперативная память, общий объем оперативной памяти, зарезервированная оперативная память, используемые ядра процессора, общее количество ядер процессора и зарезервированные ядра процессора.
В разделе Cluster Nodes Metrics показано количество активных узлов кластера, узлов, которые находятся в стадии вывода из эксплуатации, узлов, которые были выведены из эксплуатации, узлов, которые были потеряны, узлов, на которых есть проблемы, и узлов, которые были перезагружены.
В разделе User Metrics для пользователя с именем "dr.who" показана информация о приложениях, отправленных им, ожидающих выполнения, выполняющихся, завершившихся, работающих контейнерах, контейнерах, ожидающих выполнения, зарезервированных контейнерах, используемой оперативной памяти, оперативной памяти, ожидающей выполнения, зарезервированной оперативной памяти, используемых ядрах процессора, ядрах процессора, ожидающих выполнения и зарезервированных ядрах процессора. 
Далее представлены конкретные приложения с их характеристиками, такими как ID, имя, тип приложения, очередь запуска, время начала, время завершения, состояние выполнения, окончательный статус, кол-во работающих контейнеров, выделенные виртуальные ядра, выделенная память MB, зарезервированные ядра процессора, зарезервированная память и прогресс.»
КОРОЧЕ, видим выполненные вычисления и что они завершены успешно.
И последняя задачка:
Подсчитать список различных городов, посещенных каждым идентификатором грузовика, и среднюю скорость для каждого идентификатора грузовика.
Алгоритм решения:
1. Сгруппировать данные по идентификатору грузовика (truckid) с помощью оператора GROUP BY и использовать встроенную функцию Pig COUNT для подсчета уникальных городов и AVG для расчета средней скорости.
2. Использовать оператор FOREACH для создания новой структуры данных, содержащей идентификатор грузовика, количество уникальных городов и среднюю скорость.
3. Сохранить результат с помощью оператора STORE в отдельный файл.
geoloc = LOAD 'geoloc/geolocation.csv' USING PigStorage(',') AS (truckid:chararray, 
driverid:chararray, event:chararray, latitude:double, longitude:double, city:chararray, 
state:chararray, velocity:double, event_ind:long, idling_ind:long);

grouped_geoloc = GROUP geoloc BY truckid;

result = FOREACH grouped_geoloc {
    unique_cities = DISTINCT geoloc.city;
    avg_speed = AVG(geoloc.velocity);
    GENERATE group AS truckid, COUNT(unique_cities) AS num_cities_visited, avg_speed AS average_speed;
}

STORE result INTO 'results-geoloc1';

Копируем и вставляем скрипт, который выше. Если не вставляется, то вставлять частями.
И запускаем:
 
Заглянем в Oozie:
 
 
В папке появилась новая директория:
 
Зайдем в нее и далее сюда:
 
Результат:
 
1-ый столбец – идентификатор грузовика, 2-ой – количество посещенных городов, 3-ий – средняя скорость.
Чтобы выключить машину, наберите команду в терминале:
sudo shutdown now

ПОЛЕЗНЫЕ ТЕРМИНЫ
Hadoop – это свободно распространяемый набор утилит, библиотек и фреймворк для разработки и выполнения распределённых программ, работающих на кластерах из сотен и тысяч узлов. Эта основополагающая технология хранения и обработки больших данных ( Big Data ) является проектом верхнего уровня фонда Apache Software Foundation. 
Cloudera — это платформа программного обеспечения для обработки больших данных, которую выбирают представители многих отраслей. Она предоставляет клиентам такие компоненты, как Hadoop, Spark и Hive.
Apache Pig — это платформа, позволяющая создавать программы для Hadoop с помощью процедурного языка, известного как Pig Latin. Apache Pig создает более простую абстракцию процедурного языка над платформой MapReduce, чтобы реализовать SQL-подобный интерфейс для приложений Hadoop.
Apache Oozie — это серверная система планирования рабочих процессов для управления заданиями Hadoop.
YARN – это фреймворк управления ресурсами в Apache Spark, другими словами, это почти операционная система на кластерном уровне. 
